{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>gensim: another text summarizer</h3>\n",
    "Gensim uses a network with sentences as nodes and 'lexical similarity' as weights on the arcs between nodes<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import nltk\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "from nltk import sent_tokenize,word_tokenize \n",
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "community_root = \"data/community\"\n",
    "le_monde_root = \"data/le_monde\"\n",
    "community_files = \"community.*\"\n",
    "le_monde_files = \"le_monde.*\"\n",
    "heights_root = \"data/heights\"\n",
    "heights_files = \"heights.*\"\n",
    "amigos_root = \"data/amigos\"\n",
    "amigos_files = \"amigos.*\"\n",
    "community_data = PlaintextCorpusReader(community_root,community_files)\n",
    "le_monde_data = PlaintextCorpusReader(le_monde_root,le_monde_files)\n",
    "heights_data = PlaintextCorpusReader(heights_root,heights_files)\n",
    "amigos_data = PlaintextCorpusReader(amigos_root,amigos_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.corpus.reader.plaintext.PlaintextCorpusReader"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(community_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = community_data.raw()\n",
    "summary_sentences = []\n",
    "candidate_sentences = {}\n",
    "candidate_sentence_counts = {}\n",
    "striptext = text.replace('\\n\\n', ' ')\n",
    "striptext = striptext.replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim.summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We each ordered blueberry pancakes and a cup of coffee--no fresh fruit, no juice, no bacon.\n",
      "I started with a raspberry iced tea & ordered the community custom egg white omelette with sautéed spinach & mushrooms and a side of smoked salmon.\n",
      "I've come here several times with a friend for brunch and once for dinner -- we've both really enjoyed a lot of the breakfast foods available; my favorite is the brioche French toast with blackberry and lemon curd & she loves heir waffles.\n",
      "This place is really good for breakfast and has great pancakes, sausages, eggs.\n"
     ]
    }
   ],
   "source": [
    "summary = gensim.summarization.summarize(striptext, word_count=100) \n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brunch\n",
      "nice\n",
      "food\n",
      "foods\n",
      "egg\n",
      "eggs\n",
      "good\n",
      "sauced\n",
      "sauce\n",
      "sauces\n",
      "fresh\n",
      "communal\n",
      "community\n",
      "pancakes\n",
      "pancake\n",
      "little\n"
     ]
    }
   ],
   "source": [
    "print(gensim.summarization.keywords(striptext,words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I've come here several times with a friend for brunch and once for dinner -- we've both really enjoyed a lot of the breakfast foods available; my favorite is the brioche French toast with blackberry and lemon curd & she loves heir waffles.\n",
      "There are a lot of nice places in the city where you can get a very good breakfast for 1/3rd to 1/2 less than Community.\n",
      "Came here for brunch with my wife after she found the good review, and it did not disappoint!\n",
      "The beans were seasoned perfectly, as was the rest of the tomato sauce, The tortilla was fresh and soft, and it came with delicious guacamole and sour cream.\n"
     ]
    }
   ],
   "source": [
    "import naive_summary\n",
    "summary = '\\n'.join(naive_summary.build_naive_summary(community_data.raw()))\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_gensim_summary(text):\n",
    "    import gensim.summarization\n",
    "    \n",
    "    summary_sentences = []\n",
    "    candidate_sentences = {}\n",
    "    candidate_sentence_counts = {}\n",
    "    striptext = text.replace('\\n\\n', ' ')\n",
    "    striptext = striptext.replace('\\n', ' ')\n",
    "    \n",
    "    return gensim.summarization.summarize(striptext, word_count=100) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What makes us exceptional -- what makes us American -- is our allegiance to an idea articulated in a declaration made more than two centuries ago: âWe hold these truths to be self-evident, that all men are created equal; that they are endowed by their Creator with certain unalienable rights; that among these are life, liberty, and the pursuit of happiness.\n",
      "\n",
      "â     Today we continue a never-ending journey to bridge the meaning of those words with the realities of our time.\n",
      "\n",
      "\n",
      "We, the people, still believe that enduring security and lasting peace do not require perpetual war.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Obama13 = build_gensim_summary(inaugural.raw('2013-Obama.txt'))\n",
    "print('.\\n\\n'.join(Obama13.split('.')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chief Justice Roberts, President Carter, President Clinton, President Bush, President Obama, fellow Americans, and people of the world, thank you.\n",
      "\n",
      "We the citizens of America are now joined in a great national effort to rebuild our country and restore its promise for all of our people.\n",
      "\n",
      "Americans want great schools for their children, safe neighborhoods for their families, and good jobs for themselves.\n",
      "\n",
      "At the bedrock of our politics will be a total allegiance to the United States of America, and through our loyalty to our country, we will rediscover our loyalty to each other.\n",
      "\n",
      "In America, we understand that a nation is only living as long as it is striving.\n"
     ]
    }
   ],
   "source": [
    "Trump17 = build_gensim_summary(inaugural.raw('2017-Trump.txt'))\n",
    "print('\\n\\n'.join(Trump17.splitlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
